{
  "pack_id": "ch5",
  "version": "1.0.0",
  "modules": [
    {
      "id": "ch5-m01",
      "title": "Security assessment program basics",
      "tag_ids": [
        "assessment.vuln_scan_vs_pentest",
        "assessment.audit_attestation",
        "vuln_mgmt.lifecycle"
      ],
      "pages": [
        {
          "id": "ch5-m01-p01",
          "title": "What a security assessment program is",
          "content_blocks": [
            {
              "type": "explain",
              "text": "A security assessment program is the routine way an organization checks: “Are we exposed?” and “Are controls working?” \nIt’s bigger than a single tool. It mixes automated scanning, manual testing, and formal reviews."
            },
            {
              "type": "explain",
              "text": "In this chapter, the core idea is **vulnerability management**:\n1) Identify issues (scanners, assessments, reports)\n2) Analyze & prioritize (risk context, business impact)\n3) Respond & remediate (fix, reduce, accept, transfer)\n4) Validate & report (prove it’s fixed, track trends)"
            },
            {
              "type": "explain",
              "text": "Vulnerability management is continuous. Pen testing is usually time‑boxed and goal‑driven (prove impact, find paths). Audits/attestation are about demonstrating compliance or control effectiveness to a standard."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which statement best describes vulnerability management?",
              "options": [
                "A one-time penetration test performed annually",
                "A continuous cycle of finding, prioritizing, fixing, and validating vulnerabilities",
                "A compliance audit focused only on policy documents",
                "A firewall configuration change process"
              ],
              "correct_index": 1,
              "explanation": "Vulnerability management is an ongoing lifecycle: identify → analyze/prioritize → remediate → validate/report.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "What is the key difference between a vulnerability scan and a penetration test?",
              "options": [
                "A vulnerability scan is manual; penetration testing is automated",
                "A vulnerability scan lists potential issues; penetration testing attempts to prove real-world exploitability and impact",
                "Penetration testing focuses only on patching; scans focus only on passwords",
                "They are the same thing with different names"
              ],
              "correct_index": 1,
              "explanation": "Scans discover and enumerate weaknesses; penetration tests try to validate exploitation paths and business impact.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m01-p02",
          "title": "Assessments, audits, and bug bounties",
          "content_blocks": [
            {
              "type": "explain",
              "text": "You’ll hear three similar words that are *not* the same:\n- **Assessment**: broad evaluation (technical + process). Often internal or by a trusted partner.\n- **Audit**: formal check against a standard (e.g., PCI DSS). Evidence matters.\n- **Attestation**: a signed assertion that controls meet a requirement (often based on an audit)."
            },
            {
              "type": "explain",
              "text": "Some orgs also use:\n- **Responsible disclosure**: a process for outsiders to report vulnerabilities safely.\n- **Bug bounty**: a structured program that rewards valid findings.\nThese can boost coverage, but they don’t replace internal hygiene (patching, config, monitoring)."
            },
            {
              "type": "explain",
              "text": "Exam mindset: CompTIA likes “programs and processes” — the boring stuff that actually works. Tools without process = chaos with a GUI."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which activity is MOST associated with attestation?",
              "options": [
                "Running a weekly internal vulnerability scan",
                "Providing a signed statement that required controls are in place, based on formal evidence",
                "Collecting OSINT from social media",
                "Changing firewall rules during a maintenance window"
              ],
              "correct_index": 1,
              "explanation": "Attestation is a formal assertion (often signed) that requirements are met, based on evidence/audit outcomes.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "A responsible disclosure program mainly provides:",
              "options": [
                "A way to punish researchers who find bugs",
                "A safe, structured channel to report vulnerabilities and coordinate fixes",
                "A replacement for internal vulnerability scanning",
                "A method to encrypt email"
              ],
              "correct_index": 1,
              "explanation": "Responsible disclosure sets expectations and a process for reporting, triage, and coordinated remediation.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m02",
      "title": "Scoping: targets and scan perspectives",
      "tag_ids": [
        "vuln_scan.targets",
        "vuln_scan.perspective"
      ],
      "pages": [
        {
          "id": "ch5-m02-p01",
          "title": "Choosing scan targets that actually matter",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Start with **asset inventory** (what exists) and **asset criticality** (what matters). \nCommon scan targets include:\n- Endpoints (workstations, servers)\n- Network devices (routers/switches/firewalls)\n- Applications (web apps, APIs)\n- Cloud assets (instances, storage, IAM configs)"
            },
            {
              "type": "explain",
              "text": "A useful scan target definition includes:\n- Where it lives (site/VPC/subnet)\n- Owner (team/system)\n- Data sensitivity (public vs regulated)\n- Internet exposure (public-facing vs internal-only)\n- Maintenance window (when it’s safe to scan)"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: “Scan everything all the time” sounds heroic, but it’s often wrong. Scope and cadence should match risk and business impact."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which factor MOST strongly influences what you should scan first?",
              "options": [
                "The newest systems, because they are always the riskiest",
                "Asset criticality and exposure (what would hurt most if compromised)",
                "Only what is cheapest to license",
                "Only systems owned by IT"
              ],
              "correct_index": 1,
              "explanation": "Prioritize based on risk: business impact + exposure/attack surface.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m02-p02",
          "title": "Scan perspectives: internal vs external",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Your view changes what you can detect:\n- **External scan**: what an internet attacker can see and touch.\n- **Internal scan**: what a compromised insider machine could reach.\n- **Datacenter / on-prem scan**: closer to core services.\n- **Agent-based scan**: inside the host; can see local config and installed software well."
            },
            {
              "type": "explain",
              "text": "External scans may miss issues hidden behind controls (NAT, WAF, firewall, reverse proxy). \nInternal/agent/credentialed scans can reduce blind spots, but they require careful permissions and change management."
            },
            {
              "type": "explain",
              "text": "Practical rule: External finds “doors and windows.” Credentialed/agent scans find “broken locks inside the house.”"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Why might an external vulnerability scan miss a vulnerable service that is actually running?",
              "options": [
                "External scans cannot detect IP addresses",
                "Network controls (firewall/WAF/NAT) can block visibility from the outside",
                "External scans automatically patch vulnerabilities",
                "External scans always run with admin credentials"
              ],
              "correct_index": 1,
              "explanation": "External scans can be limited by perimeter controls that hide or block services from outside view.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "Which scan approach usually gives the BEST visibility into local misconfigurations on a host?",
              "options": [
                "Unauthenticated external scan",
                "Authenticated/credentialed scan or agent-based scan",
                "Passive DNS lookup",
                "Wireless site survey"
              ],
              "correct_index": 1,
              "explanation": "Credentialed or agent-based scans can inspect local configuration and installed software accurately.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m03",
      "title": "Scan frequency and scheduling",
      "tag_ids": [
        "vuln_scan.frequency",
        "vuln_scan.intrusive"
      ],
      "pages": [
        {
          "id": "ch5-m03-p01",
          "title": "Scan frequency is a risk decision",
          "content_blocks": [
            {
              "type": "explain",
              "text": "How often should you scan? There isn’t one magic number.\nFrequency is driven by:\n- Asset criticality + exposure\n- Change rate (how often systems change)\n- Threat environment\n- Compliance requirements"
            },
            {
              "type": "explain",
              "text": "Also consider practical constraints:\n- Scanner licensing and capacity\n- Network bandwidth and performance impact\n- Staff availability to triage findings\n- Maintenance windows"
            },
            {
              "type": "explain",
              "text": "Good practice: start with a baseline cadence (e.g., monthly for most, weekly for critical public systems), then tune based on risk and results."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which is the BEST reason to increase scan frequency for a system?",
              "options": [
                "It’s the newest system in the environment",
                "It is internet-facing and hosts sensitive data",
                "It belongs to a department with the largest budget",
                "It uses Windows instead of Linux"
              ],
              "correct_index": 1,
              "explanation": "Internet exposure + sensitive data = higher risk, so scan more often.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m03-p02",
          "title": "Scheduling scans safely",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Some scans are “louder” than others. Intrusive checks and aggressive plug-ins can stress systems.\nPlan for:\n- **Maintenance windows** for disruptive scans\n- Separate scanning in test/staging first if possible\n- Coordinating with owners (avoid scanning during peak business hours)"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: A scan that crashes production is a self‑inflicted denial‑of‑service. Security is supposed to reduce risk, not cosplay a disaster."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Why are maintenance windows important for certain vulnerability scans?",
              "options": [
                "They allow scans that might cause performance impact without disrupting peak operations",
                "They make scans run faster by default",
                "They ensure the scan will always find zero vulnerabilities",
                "They are required only for wireless scans"
              ],
              "correct_index": 0,
              "explanation": "Intrusive/aggressive scanning can affect performance; maintenance windows reduce business disruption.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m04",
      "title": "Scan configuration and quality",
      "tag_ids": [
        "vuln_scan.maintenance",
        "vuln_scan.intrusive",
        "vuln_scan.fp_fn"
      ],
      "pages": [
        {
          "id": "ch5-m04-p01",
          "title": "Scan configuration: templates, plugins, and sensitivity",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Scanners typically use profiles/templates:\n- Discovery only vs full vulnerability scan\n- Web app scan vs network scan\n- Credentialed vs non‑credentialed"
            },
            {
              "type": "explain",
              "text": "Most scanners also rely on a plugin/signature feed. If plugins are stale, results degrade (misses + false positives).\nYou can tune sensitivity to trade off between:\n- Coverage (catch more) \n- Noise (investigate more) \n- Stability (avoid breaking things)"
            },
            {
              "type": "explain",
              "text": "Practical: tune *per target group*. A dev lab can handle aggressive scans; a fragile legacy system may need careful settings."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "A vulnerability scanner’s plugins are outdated. What is the MOST likely impact?",
              "options": [
                "The scanner will encrypt all findings",
                "The scanner may miss newer vulnerabilities or misidentify services",
                "The scanner automatically becomes credentialed",
                "The scanner will only run externally"
              ],
              "correct_index": 1,
              "explanation": "Outdated plugins reduce detection accuracy and can increase false positives/negatives.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m04-p02",
          "title": "Intrusive scanning and reducing false positives",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Intrusive scanning can include active exploitation checks, brute-force style probes, or heavy request volumes.\nUse it when you need confidence, but:\n- Coordinate with owners\n- Prefer test/staging first\n- Use rate limiting / safe settings"
            },
            {
              "type": "explain",
              "text": "False positives happen. Reduce them by:\n- Using credentialed scans where possible\n- Verifying with a second method (log check, config review, manual validation)\n- Understanding how controls (WAF, proxies) alter what the scanner sees"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which action MOST directly reduces false positives in vulnerability scanning?",
              "options": [
                "Turning off all plugins",
                "Using a credentialed scan and validating high-risk findings",
                "Scanning only during business hours",
                "Deleting the scan report"
              ],
              "correct_index": 1,
              "explanation": "Credentialed scans and validation improve accuracy and reduce false positives.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m05",
      "title": "Credentialed and agent-based scans",
      "tag_ids": [
        "vuln_scan.credentialed",
        "vuln_scan.agent_based"
      ],
      "pages": [
        {
          "id": "ch5-m05-p01",
          "title": "Credentialed scanning (authenticated scanning)",
          "content_blocks": [
            {
              "type": "explain",
              "text": "**Credentialed scanning** logs into the target (or uses an authenticated method) to check:\n- Installed software versions\n- Patch levels\n- Local configuration (services, registry, permissions)"
            },
            {
              "type": "explain",
              "text": "It’s usually more accurate than purely remote checks. \nSecurity note: use least privilege accounts where possible; store creds securely; rotate regularly."
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: Credentialed scanning increases visibility, but it also increases *credential risk*. Treat scanner credentials like crown jewels."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the PRIMARY advantage of credentialed vulnerability scanning?",
              "options": [
                "It guarantees exploitation will succeed",
                "It provides deeper, more accurate insight into local configuration and patch state",
                "It prevents DDoS attacks",
                "It works only on wireless networks"
              ],
              "correct_index": 1,
              "explanation": "Credentialed scans can inspect local state and patch levels more reliably than remote-only scans.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m05-p02",
          "title": "Agent-based scanning",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Agent-based scanners install a small agent on hosts. Benefits:\n- Works even when hosts are off-network or behind NAT\n- Strong visibility into local software/config\n- Often supports continuous assessment"
            },
            {
              "type": "explain",
              "text": "Tradeoffs:\n- Deployment effort and ongoing agent management\n- Potential endpoint performance impact\n- Must trust the agent pipeline (updates, integrity)"
            },
            {
              "type": "explain",
              "text": "Practical rollout: pilot on a small set of systems, validate impact, then expand."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "When is agent-based scanning MOST useful?",
              "options": [
                "For systems that frequently leave the corporate network (remote laptops)",
                "Only for public-facing web servers",
                "Only for network devices like routers",
                "Only when you want unauthenticated scanning"
              ],
              "correct_index": 0,
              "explanation": "Agents help assess hosts that are off-network/remote and provide deep local visibility.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m06",
      "title": "SCAP and scanning/testing tools",
      "tag_ids": [
        "scap",
        "vuln_scan.maintenance",
        "cve"
      ],
      "pages": [
        {
          "id": "ch5-m06-p01",
          "title": "Scanner maintenance and why it matters",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Scanners are not “set and forget.” Maintenance includes:\n- Updating plugin/signature feeds\n- Updating scanner software\n- Validating that scans run with the right profiles"
            },
            {
              "type": "explain",
              "text": "Bad maintenance leads to:\n- Missing new vulnerabilities (false negatives)\n- Misidentifying services (false positives)\n- Slower triage because results don’t match reality"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Why is scanner maintenance (updates, plugins) important?",
              "options": [
                "It makes scans more colorful in the UI",
                "It improves detection accuracy and reduces false positives/negatives",
                "It allows scanning without network access",
                "It replaces patch management"
              ],
              "correct_index": 1,
              "explanation": "Updated scanners and plugins improve detection coverage and reliability.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m06-p02",
          "title": "SCAP: standardizing security content",
          "content_blocks": [
            {
              "type": "explain",
              "text": "**SCAP (Security Content Automation Protocol)** is a collection of standards for describing:\n- vulnerabilities,\n- configurations,\n- and compliance checks\n…in a consistent way that tools can exchange."
            },
            {
              "type": "explain",
              "text": "SCAP-related pieces you may see:\n- **CVE**: IDs for known vulnerabilities\n- **CPE**: standardized names for products/platforms\n- **CCE**: IDs for configuration issues\n- **OVAL/XCCDF**: formats for expressing checks and compliance rules"
            },
            {
              "type": "explain",
              "text": "Exam note: SCAP is about **automation and standardization**—making security checking repeatable."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the main purpose of SCAP?",
              "options": [
                "To provide end-to-end encryption for VPNs",
                "To standardize and automate the exchange of security check/vulnerability/compliance content",
                "To block phishing emails",
                "To replace SIEM logging"
              ],
              "correct_index": 1,
              "explanation": "SCAP is a framework of standards for consistent security configuration/vulnerability/compliance automation.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m06-p03",
          "title": "Common vulnerability and application testing tools",
          "content_blocks": [
            {
              "type": "explain",
              "text": "On Security+, you’ll see tool categories more than brand names:\n- Network vulnerability scanners\n- Web application scanners\n- SAST/DAST (code vs running app testing)\n- Configuration compliance tools"
            },
            {
              "type": "explain",
              "text": "Typical examples in the wild (not exhaustive):\n- Nessus / OpenVAS style vuln scanners\n- Burp/ZAP style web scanners\n- SAST in CI pipelines (static analysis)\n- DAST against staging environments"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: A “scanner” finding is not automatically “true.” It’s a lead. You still validate and prioritize."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which tool type tests an application while it is running (from the outside)?",
              "options": [
                "SAST (Static Application Security Testing)",
                "DAST (Dynamic Application Security Testing)",
                "CVE",
                "SCAP"
              ],
              "correct_index": 1,
              "explanation": "DAST tests a running application externally; SAST analyzes code without running it.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m07",
      "title": "Scan reports, CVE/CVSS, and FP/FN",
      "tag_ids": [
        "vuln_scan.fp_fn",
        "cve",
        "cvss.base",
        "cvss.severity_scale"
      ],
      "pages": [
        {
          "id": "ch5-m07-p01",
          "title": "Interpreting scan reports",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Scan reports usually include:\n- Asset identifier (host/IP/app)\n- Finding (vulnerability/config issue)\n- Evidence (banner, version, response, config state)\n- Severity (often CVSS-based)\n- Remediation guidance"
            },
            {
              "type": "explain",
              "text": "A scanner may show a service as “unknown” or mis-versioned if controls interfere (WAF, reverse proxy, filtering). That’s why evidence and validation matter."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the MOST important field when deciding whether to trust a scan finding?",
              "options": [
                "The logo of the scanning vendor",
                "Evidence that supports the finding (banner, response, config state)",
                "The color used in the PDF report",
                "The number of pages in the report"
              ],
              "correct_index": 1,
              "explanation": "Evidence helps you validate whether the finding is real or a false positive.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m07-p02",
          "title": "CVE vs CVSS (don’t mix them up)",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Two terms that people confuse:\n- **CVE**: the identifier (the “name” of a known vulnerability).\n- **CVSS**: the scoring system that estimates severity/impact (the “how bad”)."
            },
            {
              "type": "explain",
              "text": "CVSS has metrics and produces a score often mapped to a severity label (Low/Medium/High/Critical).\nBut your organization may still prioritize differently based on real context (exposed? exploited? business critical?)."
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: CVSS score ≠ your priority. Context can override score."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What does a CVE provide?",
              "options": [
                "A severity score from 0 to 10",
                "A unique identifier for a publicly known vulnerability",
                "A method to exploit a target automatically",
                "A replacement for patch management"
              ],
              "correct_index": 1,
              "explanation": "CVE is an identifier; CVSS is the scoring system.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "What does CVSS primarily represent?",
              "options": [
                "The name of a vulnerability",
                "A standardized severity scoring method",
                "A type of vulnerability scanner",
                "A cryptographic algorithm"
              ],
              "correct_index": 1,
              "explanation": "CVSS is a scoring system used to estimate severity/impact.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m07-p03",
          "title": "False positives and false negatives",
          "content_blocks": [
            {
              "type": "explain",
              "text": "- **False positive**: flagged as vulnerable, but it’s not.\n- **False negative**: vulnerable, but the scan missed it."
            },
            {
              "type": "explain",
              "text": "You reduce errors by:\n- Credentialed/agent scans\n- Tuning scan profiles\n- Validating critical findings manually or with a second tool\n- Keeping plugins updated"
            },
            {
              "type": "explain",
              "text": "Real-world pattern: false negatives are scarier (unknown exposure), but false positives waste time and can burn trust in the program."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "A scanner reports a critical vulnerability, but manual verification shows the system is patched. This is a:",
              "options": [
                "False negative",
                "False positive",
                "Zero-day",
                "Logic bomb"
              ],
              "correct_index": 1,
              "explanation": "Flagged as vulnerable but isn't = false positive.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m08",
      "title": "Vulnerability analysis and prioritization",
      "tag_ids": [
        "risk.context",
        "cvss.severity_scale",
        "cvss.base"
      ],
      "pages": [
        {
          "id": "ch5-m08-p01",
          "title": "From findings to risk: analysis and prioritization",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Analysis means translating a finding into “so what?”\nYou typically consider:\n- Severity (CVSS/severity label)\n- Exploitability (is there a known exploit? is it being exploited?)\n- Exposure (internet-facing? reachable internally?)\n- Asset value (how bad if this host/app is compromised?)"
            },
            {
              "type": "explain",
              "text": "Security+ likes the idea that prioritization is **risk-based**, not “highest CVSS first.”"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Two vulnerabilities have the same CVSS score. Which should usually be fixed first?",
              "options": [
                "The one on the system with no sensitive data and no network access",
                "The one on an internet-facing system that processes sensitive data",
                "Always choose randomly to avoid bias",
                "Always choose the newest CVE"
              ],
              "correct_index": 1,
              "explanation": "Risk context (exposure + business impact) drives priority when scores are similar.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m08-p02",
          "title": "Risk context: exposure factor and environmental variables",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Organizations often refine severity using context:\n- **Exposure factor**: how exposed the asset is (public vs internal, segmented vs flat).\n- **Environmental variables**: compensating controls, monitoring, exploit availability, business impact."
            },
            {
              "type": "explain",
              "text": "Example:\nA Medium CVSS issue on a public login portal might outrank a High CVSS issue on a lab machine behind strong segmentation."
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: “Severity” is a starting point. “Risk” is severity + likelihood + impact."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which term BEST matches: “How reachable and exposed is this vulnerable asset?”",
              "options": [
                "Exposure factor",
                "Non-repudiation",
                "Key stretching",
                "Perfect forward secrecy"
              ],
              "correct_index": 0,
              "explanation": "Exposure factor describes how exposed/reachable the asset is, affecting real-world risk.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m08-p03",
          "title": "Severity labels and what they mean in practice",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Many tools map CVSS scores into labels like:\n- Low / Medium / High / Critical\nLabels are helpful for triage, but don’t let them replace thinking."
            },
            {
              "type": "explain",
              "text": "Good practice:\n- Define SLAs (fix timelines) per severity AND exposure.\n- Track trends over time (is overall risk decreasing?)."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Why can severity labels be misleading if used alone?",
              "options": [
                "They are always computed incorrectly",
                "They may not include organizational context like exposure and business impact",
                "They are illegal to use in audits",
                "They only apply to malware"
              ],
              "correct_index": 1,
              "explanation": "Severity labels are generic; real priority depends on your environment and business impact.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m09",
      "title": "Vulnerability response and remediation",
      "tag_ids": [
        "remediation.options",
        "remediation.validation",
        "risk.context"
      ],
      "pages": [
        {
          "id": "ch5-m09-p01",
          "title": "Response options: fix, reduce, accept, transfer",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Common remediation options:\n- **Patching / updating** (remove the vulnerability)\n- **Configuration change** (disable weak protocols, restrict access)\n- **Segmentation / isolation** (reduce exposure)\n- **Compensating controls** (WAF rules, monitoring, MFA)\n- **Accept risk** (documented exception)\n- **Transfer risk** (insurance/contracts)"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: “Accept risk” isn’t laziness. It’s a documented decision with business ownership."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which action is an example of a compensating control?",
              "options": [
                "Applying a vendor patch",
                "Adding WAF rules and enhanced monitoring until patching is possible",
                "Deleting the vulnerability report",
                "Turning off all logging"
              ],
              "correct_index": 1,
              "explanation": "Compensating controls reduce risk when you can’t immediately remove the underlying vulnerability.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m09-p02",
          "title": "Exceptions and exemptions",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Sometimes you cannot patch immediately (legacy systems, vendor constraints, downtime risk).\nIn that case, use a formal process:\n- record the vulnerability and justification\n- add compensating controls\n- define an expiration/review date\n- assign an accountable owner"
            },
            {
              "type": "explain",
              "text": "This prevents “temporary” exceptions from living forever and becoming permanent holes."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the BEST practice when a vulnerability cannot be patched immediately?",
              "options": [
                "Ignore it until the next annual audit",
                "Create a documented exception with compensating controls and a review/expiration date",
                "Disable all security controls to reduce false positives",
                "Run a penetration test instead of fixing it"
              ],
              "correct_index": 1,
              "explanation": "A documented exception + compensating controls + review date is standard practice for unpatchable issues.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m10",
      "title": "Validation, reporting, threat hunting, and audits",
      "tag_ids": [
        "remediation.validation",
        "threat_hunting",
        "third_party_risk.assessment",
        "assessment.internal_external",
        "assessment.audit_attestation"
      ],
      "pages": [
        {
          "id": "ch5-m10-p01",
          "title": "Validation: prove the fix worked",
          "content_blocks": [
            {
              "type": "explain",
              "text": "After remediation, you validate:\n- Re-scan / re-test the affected asset\n- Verify configuration or patch level\n- Confirm the exposure is reduced (e.g., port closed, access limited)"
            },
            {
              "type": "explain",
              "text": "Validation also helps catch:\n- partial fixes\n- rollbacks\n- “fixed in prod? fixed in staging?” drift"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the MOST direct way to validate that a vulnerability was remediated?",
              "options": [
                "Assume it is fixed after the ticket is closed",
                "Re-scan or re-test and verify the evidence no longer indicates vulnerability",
                "Wait for a user complaint",
                "Disable the scanner"
              ],
              "correct_index": 1,
              "explanation": "Validation requires evidence, typically via re-scan/re-test and verification.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m10-p02",
          "title": "Reporting: turning results into action",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Reporting answers:\n- What is our risk posture now?\n- What changed since last period?\n- Which teams/systems need attention?\nGood reports include trends, top recurring issues, and SLA compliance."
            },
            {
              "type": "explain",
              "text": "Reporting should be tuned to audience:\n- Engineers want evidence + fix steps.\n- Leadership wants risk trend + business impact."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which report element is MOST useful for leadership?",
              "options": [
                "Raw port scan output for every host",
                "Trend of risk posture over time and the business impact of top issues",
                "Exact packet captures of scan traffic",
                "The scanner’s internal debug logs"
              ],
              "correct_index": 1,
              "explanation": "Leadership needs trend + impact, not raw technical noise.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m10-p03",
          "title": "Threat hunting, third-party risk, and audits",
          "content_blocks": [
            {
              "type": "explain",
              "text": "**Threat hunting** is proactive searching for threats that may have slipped past controls. \nInstead of waiting for an alert, hunters use hypotheses (e.g., “Do we have C2 traffic?”) and investigate."
            },
            {
              "type": "explain",
              "text": "Third-party risk assessment asks: “What risks do vendors/partners introduce?”\nCommon checks: security questionnaires, contract requirements, evidence reviews, and sometimes independent audits."
            },
            {
              "type": "explain",
              "text": "Internal vs external assessments:\n- Internal: done by your org (fast feedback).\n- External/third-party: independent view (credibility, compliance)."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Threat hunting is BEST described as:",
              "options": [
                "Waiting for the SIEM to alert and then investigating",
                "Proactively searching for signs of compromise based on hypotheses and data",
                "Only running vulnerability scans",
                "A type of encryption"
              ],
              "correct_index": 1,
              "explanation": "Threat hunting is proactive search, not reactive alert handling.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "Why are third-party assessments commonly performed?",
              "options": [
                "To avoid patching internal systems",
                "To evaluate the security risk introduced by vendors and partners",
                "To increase Wi-Fi range",
                "To replace incident response"
              ],
              "correct_index": 1,
              "explanation": "Vendors can introduce risk; assessments help understand and manage that risk.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    },
    {
      "id": "ch5-m11",
      "title": "Penetration testing essentials",
      "tag_ids": [
        "pentest.roe",
        "pentest.knowledge_levels",
        "pentest.recon",
        "pentest.post_exploitation",
        "pentest.reporting"
      ],
      "pages": [
        {
          "id": "ch5-m11-p01",
          "title": "Rules of engagement (RoE): permission, scope, limits",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Pen tests must be governed by **Rules of Engagement**:\n- written authorization\n- scope (targets, networks, apps, physical locations)\n- allowed techniques (e.g., social engineering allowed or not)\n- time windows, notification rules, and safety constraints"
            },
            {
              "type": "explain",
              "text": "RoE protects both sides:\n- testers avoid legal/operational landmines\n- the org avoids surprise outages and unapproved activity"
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "What is the PRIMARY purpose of rules of engagement in penetration testing?",
              "options": [
                "To guarantee exploitation success",
                "To define authorized scope, permissions, and limitations to manage risk and legality",
                "To update vulnerability scanner plugins",
                "To encrypt scan reports"
              ],
              "correct_index": 1,
              "explanation": "RoE defines scope/permission/limits, ensuring legality and minimizing business disruption.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m11-p02",
          "title": "Pen test types and knowledge levels",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Pen tests can be categorized by approach:\n- **Offensive**: attacker-style exploitation\n- **Defensive**: validate detection/response\n- **Integrated**: coordinated with defenders (often “purple team” style)"
            },
            {
              "type": "explain",
              "text": "And by how much the testers know:\n- **Known environment (white box)**: lots of details provided\n- **Partially known (gray box)**\n- **Unknown (black box)**: minimal info"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: Unknown/black box tests realism, but can be slower and miss internal issues. Known/white box tests depth."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "A penetration test performed with minimal information about the target environment is a:",
              "options": [
                "Known environment (white box) test",
                "Unknown environment (black box) test",
                "Credentialed scan",
                "SCAP assessment"
              ],
              "correct_index": 1,
              "explanation": "Black box = unknown environment; white box = known environment.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m11-p03",
          "title": "Reconnaissance and post-exploitation basics",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Reconnaissance (recon) gathers information:\n- **Passive recon**: without direct interaction (OSINT, DNS records, public info)\n- **Active recon**: touching the target (scanning, probing)"
            },
            {
              "type": "explain",
              "text": "Wireless recon examples:\n- **War driving**: searching for Wi‑Fi networks by driving around\n- **War flying**: same concept using aerial methods"
            },
            {
              "type": "explain",
              "text": "Post-exploitation ideas you’ll see:\n- privilege escalation\n- lateral movement/pivoting\n- maintaining access (persistence)\n- exfiltration simulation\nThen: clean up and report."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which action is an example of passive reconnaissance?",
              "options": [
                "Port scanning a target subnet",
                "Querying public WHOIS/DNS information about a domain",
                "Running a vulnerability exploit module",
                "Attempting credential brute force"
              ],
              "correct_index": 1,
              "explanation": "Passive recon collects info without directly probing the target systems.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            },
            {
              "type": "single_choice",
              "prompt": "What is 'pivoting' in a penetration test?",
              "options": [
                "Switching from Wi-Fi to Ethernet",
                "Using a compromised system to access and attack other internal systems",
                "Creating a CVE identifier",
                "Updating a scanner plugin feed"
              ],
              "correct_index": 1,
              "explanation": "Pivoting/lateral movement uses an initial foothold to reach deeper internal targets.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        },
        {
          "id": "ch5-m11-p04",
          "title": "Reporting and retesting",
          "content_blocks": [
            {
              "type": "explain",
              "text": "Pen test reporting should include:\n- executive summary (risk and impact)\n- technical details (steps, evidence, affected systems)\n- remediation recommendations\n- retest/validation plan"
            },
            {
              "type": "explain",
              "text": "EXAM TRAP: “Found it” isn’t the end. The value is in clear reporting and actionable remediation."
            }
          ],
          "checks": [
            {
              "type": "single_choice",
              "prompt": "Which is MOST important in a penetration test report for engineering teams?",
              "options": [
                "A dramatic story with no evidence",
                "Reproducible steps, evidence, and clear remediation guidance",
                "Only a CVSS score",
                "A list of all tools used without context"
              ],
              "correct_index": 1,
              "explanation": "Engineers need reproducible evidence and actionable remediation to fix issues.",
              "objectiveIds": [
                "1.1",
                "1.3",
                "2.1",
                "2.2",
                "2.3",
                "3.1",
                "3.2",
                "3.4",
                "4.2",
                "4.3",
                "4.8",
                "5.1",
                "5.2",
                "5.3",
                "5.4"
              ]
            }
          ],
          "objectiveIds": [
            "1.1",
            "1.3",
            "2.1",
            "2.2",
            "2.3",
            "3.1",
            "3.2",
            "3.4",
            "4.2",
            "4.3",
            "4.8",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
          ]
        }
      ],
      "objectiveIds": [
        "1.1",
        "1.3",
        "2.1",
        "2.2",
        "2.3",
        "3.1",
        "3.2",
        "3.4",
        "4.2",
        "4.3",
        "4.8",
        "5.1",
        "5.2",
        "5.3",
        "5.4"
      ]
    }
  ],
  "objectiveIds": [
    "1.1",
    "1.3",
    "2.1",
    "2.2",
    "2.3",
    "3.1",
    "3.2",
    "3.4",
    "4.2",
    "4.3",
    "4.8",
    "5.1",
    "5.2",
    "5.3",
    "5.4"
  ]
}